{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LR0hN2fHLZkQ",
        "XQlFZCaol56h",
        "2dMpaTqIh6Fo",
        "bjSc0_8AiwUt",
        "0y8SoX9gj__0",
        "Wx3G-cYCkiAc",
        "L72reSFsPVIF"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-war85LmrlP"
      },
      "source": [
        "!pip install tensorboardX\n",
        "!pip install transformers -q\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PytaUpHXmsdC"
      },
      "source": [
        "!pip install  datasets  rouge-score nltk\n",
        "from datasets import load_dataset, load_metric\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "metric = load_metric(\"rouge\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIoeoFfVyPyT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR0hN2fHLZkQ"
      },
      "source": [
        "# Dataset Class for AMI corpus "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xKClKuxrEXy"
      },
      "source": [
        "class AmiMeetingDataset(Dataset):\n",
        "  def __init__(self,data, tokenizer,source_len,summary_len):\n",
        "    super(AmiMeetingDataset,self).__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_len  = source_len\n",
        "    self.summary_len = summary_len \n",
        "\n",
        "    self.document = self.data.meeting\n",
        "    self.summary = self.data.Summary\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.document)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text = str(self.document[idx])\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    summ = str(self.summary[idx])\n",
        "    summ = \" \".join(summ.split())\n",
        "\n",
        "    # source = self.tokenizer.batch_encode_plus([text],max_length=self.source_len,\n",
        "    #                                          pad_to_max_length = True,return_tensors ='pt' )\n",
        "    # target = self.tokenizer.batch_encode_plus([summ],max_length = self.summary_len,\n",
        "    #                                           pad_to_max_length=True,return_tensors='pt')\n",
        "    \n",
        "    source = self.tokenizer(text, max_length=self.source_len, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(summ, max_length= self.summary_len, truncation=True)\n",
        "\n",
        "    \n",
        "    # source_ids = source['input_ids'].squeeze()\n",
        "    # source_mask = source['attention_mask'].squeeze()\n",
        "\n",
        "    # target_ids = target['input_ids'].squeeze()\n",
        "    # target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "       \n",
        "    source_ids = source['input_ids']\n",
        "    source_mask = source['attention_mask']\n",
        "\n",
        "    target_ids =labels['input_ids']\n",
        "    target_mask = labels['attention_mask']\n",
        "    \n",
        "    return {\n",
        "        'input_ids': source_ids,\n",
        "        'attention_mask': source_mask,\n",
        "        'labels': target_ids\n",
        "        # 'target_mask': target_mask,\n",
        "\n",
        "    }\n",
        "\n",
        "    # return {\n",
        "    #     'source_ids': torch.tensor(source_ids,dtype = torch.long),\n",
        "    #     'source_mask': torch.tensor(source_mask,dtype = torch.long),\n",
        "    #     'target_ids': torch.tensor(target_mask,dtype = torch.long),\n",
        "    #     'target_mask': torch.tensor(target_mask,dtype = torch.long),\n",
        "\n",
        "    # }\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLumrYI4qcQF"
      },
      "source": [
        "class AmiMeetingDatasetVAL(Dataset):\n",
        "  def __init__(self,data, tokenizer,source_len,summary_len):\n",
        "    super(AmiMeetingDatasetVAL,self).__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_len  = source_len\n",
        "    self.summary_len = summary_len \n",
        "\n",
        "    self.document = self.data.meeting\n",
        "    self.summary = self.data.Summary\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.document)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text = str(self.document[idx])\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    summ = str(self.summary[idx])\n",
        "    summ = \" \".join(summ.split())\n",
        "\n",
        "    # source = self.tokenizer.batch_encode_plus([text],max_length=self.source_len,\n",
        "    #                                          pad_to_max_length = True,return_tensors ='pt' )\n",
        "    # target = self.tokenizer.batch_encode_plus([summ],max_length = self.summary_len,\n",
        "    #                                           pad_to_max_length=True,return_tensors='pt')\n",
        "    \n",
        "    source = self.tokenizer(text, max_length=self.source_len, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(summ, max_length= self.summary_len, truncation=True)\n",
        "\n",
        "    \n",
        "    # source_ids = source['input_ids'].squeeze()\n",
        "    # source_mask = source['attention_mask'].squeeze()\n",
        "\n",
        "    # target_ids = target['input_ids'].squeeze()\n",
        "    # target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "       \n",
        "    source_ids = source['input_ids']\n",
        "    source_mask = source['attention_mask']\n",
        "\n",
        "    target_ids =labels['input_ids']\n",
        "    target_mask = labels['attention_mask']\n",
        "    \n",
        "    return {\n",
        "        'input_ids': source_ids,\n",
        "        'labels': target_ids\n",
        "\n",
        "    }\n",
        "\n",
        "    # return {\n",
        "    #     'source_ids': torch.tensor(source_ids,dtype = torch.long),\n",
        "    #     'source_mask': torch.tensor(source_mask,dtype = torch.long),\n",
        "    #     'target_ids': torch.tensor(target_mask,dtype = torch.long),\n",
        "    #     'target_mask': torch.tensor(target_mask,dtype = torch.long),\n",
        "\n",
        "    # }\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQMzLjPLhd-Z"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/Train_data.csv\")\n",
        "valid_df = pd.read_csv(\"/content/Valid_data.csv\")\n",
        "test_df = pd.read_csv(\"/content/Test_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dMpaTqIh6Fo"
      },
      "source": [
        "# T5 *Pytorch_Lightning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo_bts_bCK0"
      },
      "source": [
        "!pip install -q transformers==4.5.0\n",
        "!pip install -q pytorch_lightning==1.2.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqfdPs3iiCz9"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pathlib import Path\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "import textwrap\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast as T5Tokenizer\n",
        ")\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2VeC1tYiEy2"
      },
      "source": [
        "pl.seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcKp8dUqiJVo"
      },
      "source": [
        "train_df = pd.read_csv(\"Train_data.csv\")\n",
        "valid_df = pd.read_csv(\"Valid_data.csv\")\n",
        "test_df = pd.read_csv(\"Test_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFE00naOiMJ-"
      },
      "source": [
        "class AmiMeetingDataset(Dataset):\n",
        "  def __init__(self,data, tokenizer,source_len,summary_len):\n",
        "    super(AmiMeetingDataset,self).__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_len  = source_len\n",
        "    self.summary_len = summary_len \n",
        "\n",
        "    self.document = self.data.meeting\n",
        "    self.summary = self.data.Summary\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.document)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text = str(self.document[idx])\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    summ = str(self.summary[idx])\n",
        "    summ = \" \".join(summ.split())\n",
        "\n",
        "\n",
        "    source = self.tokenizer(\n",
        "        text,\n",
        "        max_length = self.source_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "\n",
        "    target = self.tokenizer(\n",
        "        summ,\n",
        "        max_length = self.summary_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "\n",
        "    labels = target[\"input_ids\"]\n",
        "    # FOR PAD TOKEN REPLACE WITH -100\n",
        "    labels[labels==0] = -100\n",
        "\n",
        "    return dict(\n",
        "        text = text,\n",
        "        summary = summ,\n",
        "        text_input_ids = source[\"input_ids\"].flatten(),\n",
        "        text_attention_mask = source[\"attention_mask\"].flatten(),\n",
        "        labels = labels.flatten(),\n",
        "        labels_attention_mask = target[\"attention_mask\"].flatten()\n",
        "    )\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRwtTBe-iVNc"
      },
      "source": [
        "class AMIMeetingDataModule(pl.LightningDataModule):\n",
        "  def __init__(self,train_df,valid_df,tokenizer,batch_size,source_max_len,target_max_len):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.valid_df = valid_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.source_max = source_max_len\n",
        "    self.target_max = target_max_len\n",
        "\n",
        "\n",
        "  def setup(self,stage=None):\n",
        "    self.train_dataset = AmiMeetingDataset(\n",
        "        self.train_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max,\n",
        "        self.target_max\n",
        "    )\n",
        "\n",
        "    self.valid_dataset = AmiMeetingDataset(\n",
        "        self.valid_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max,\n",
        "        self.target_max\n",
        "    )\n",
        "     \n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size = self.batch_size,\n",
        "        shuffle = True,\n",
        "        num_workers = 2 # in COLAB\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.valid_dataset,\n",
        "        batch_size = self.batch_size,\n",
        "        shuffle = False,\n",
        "        num_workers = 2 # in COLAB\n",
        "    )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.valid_dataset,\n",
        "        batch_size = self.batch_size,\n",
        "        shuffle = False,\n",
        "        num_workers = 2 # in COLAB\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALuxQspPiV6w"
      },
      "source": [
        "model_name = \"t5-base\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYF6Z9-FiXTJ"
      },
      "source": [
        "epochs = 3 \n",
        "batch_size = 4\n",
        "\n",
        "data_module = AMIMeetingDataModule(train_df,valid_df,tokenizer,batch_size=batch_size,source_max_len=512,target_max_len=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7d23daiiav6"
      },
      "source": [
        "class SummModel(pl.LightningModule):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(model_name,return_dict =True)\n",
        "\n",
        "  def forward(self,input_ids,attention_mask,decoder_attention_mask,labels = None):\n",
        "\n",
        "    out =  self.model(\n",
        "        input_ids,\n",
        "        attention_mask =attention_mask,\n",
        "        labels =labels,\n",
        "        decoder_attention_mask = decoder_attention_mask\n",
        "    )\n",
        "\n",
        "    return out.loss,out.logits\n",
        "\n",
        "\n",
        "  def training_step(self,batch,batch_idx):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss,outputs = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        decoder_attention_mask = labels_attention_mask,\n",
        "        labels =labels\n",
        "    )\n",
        "\n",
        "    self.log(\"train_loss\",loss,prog_bar =True,logger =True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self,batch,batch_idx):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss,outputs = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        decoder_attention_mask = labels_attention_mask,\n",
        "        labels =labels\n",
        "    )\n",
        "\n",
        "    self.log(\"val_loss\",loss,prog_bar =True,logger =True)\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def test_step(self,batch,batch_idx):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss,outputs = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        decoder_attention_mask = labels_attention_mask,\n",
        "        labels =labels\n",
        "    )\n",
        "\n",
        "    self.log(\"test_loss\",loss,prog_bar =True,logger =True)\n",
        "    return loss\n",
        "\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(),lr = 5e-4)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_VjWAXEib8X"
      },
      "source": [
        "model = SummModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpR_VMgiiddu"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO7M6qbmieo_"
      },
      "source": [
        "# epochs = 3\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = \"checkpoints\",\n",
        "    filename = \"best-checkpoint\",\n",
        "    save_top_k= 1 ,\n",
        "    verbose = True,\n",
        "    monitor = \"val_loss\",\n",
        "    mode = \"min\"\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"ligthning_logs\",name = \"AMI meeting Summary\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    logger = logger,\n",
        "    checkpoint_callback = checkpoint_callback,\n",
        "    max_epochs = epochs,\n",
        "    gpus =1 ,\n",
        "    progress_bar_refresh_rate = 30\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXMYqWOpigYe"
      },
      "source": [
        "trainer.fit(model,data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk9ifeMFiheE"
      },
      "source": [
        "trained_model = SummModel.load_from_checkpoint(\n",
        "    trainer.checkpoint_callback.best_model_path\n",
        ")\n",
        "\n",
        "trained_model.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP_YvDSfiib5"
      },
      "source": [
        "def summarize(text):\n",
        "  source = tokenizer(\n",
        "      text,\n",
        "      max_length = 512,\n",
        "      padding = \"max_length\",\n",
        "      add_special_tokens = True,\n",
        "      truncation = True,\n",
        "      return_attention_mask =True,\n",
        "      return_tensors = \"pt\"\n",
        "  )\n",
        "\n",
        "  gen_ids = trained_model.model.generate(\n",
        "      input_ids = source[\"input_ids\"],\n",
        "      attention_mask = source[\"attention_mask\"],\n",
        "      max_length = 150,\n",
        "      num_beams = 2,\n",
        "      repetition_penalty = 2.5,\n",
        "      length_penalty = 1.0,\n",
        "      early_stopping = True\n",
        "  )\n",
        "\n",
        "  preds = [\n",
        "           tokenizer.decode(gen_id , skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "           for gen_id in gen_ids\n",
        "  ]\n",
        "\n",
        "  return \"\".join(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETxeEQKikKC"
      },
      "source": [
        "meetings = test_df.meeting.tolist()\n",
        "preds = []\n",
        "actual = []\n",
        "for i in range(len(meetings)):\n",
        "  summ = summarize(test_df.iloc[i][\"meeting\"])\n",
        "  preds.append(summ)\n",
        "  actual.append(test_df.iloc[i][\"Summary\"])\n",
        "\n",
        "my_dict = {\n",
        "    \"preds\" : preds,\n",
        "    \"actual\" : actual\n",
        "}\n",
        "\n",
        "dfs = pd.DataFrame(my_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GialJPrGipIz"
      },
      "source": [
        "metric.compute(predictions = dfs.preds.tolist(),references=dfs.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbOLVjGYirjT"
      },
      "source": [
        "dfs.to_csv(\"Predictions_T5_3.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjSc0_8AiwUt"
      },
      "source": [
        "# Different Models(BART) using Huggingface example code(Results at end)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsT6ldQzX12s",
        "outputId": "15841983-0dcc-4ca2-df40-a5453dac24dc"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 72664, done.\u001b[K\n",
            "remote: Counting objects: 100% (700/700), done.\u001b[K\n",
            "remote: Compressing objects: 100% (365/365), done.\u001b[K\n",
            "remote: Total 72664 (delta 400), reused 505 (delta 295), pack-reused 71964\u001b[K\n",
            "Receiving objects: 100% (72664/72664), 56.10 MiB | 29.32 MiB/s, done.\n",
            "Resolving deltas: 100% (51536/51536), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-NuGw-CjDQ6"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q57ddKeVYSfb",
        "outputId": "a9f20f60-31f4-4e1a-db7f-7e33164a21cc"
      },
      "source": [
        "cd transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCIeO8HdYekj"
      },
      "source": [
        "!python examples/pytorch/summarization/run_summarization.py \\\n",
        "    --model_name_or_path facebook/bart-large-xsum  \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --train_file Train_data.csv \\\n",
        "    --validation_file Valid_data.csv \\\n",
        "    --output_dir ./bart-large-5 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size=4 \\\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --predict_with_generate  \\\n",
        "    --num_train_epochs=5 \\\n",
        "    --max_source_length=1024 \\\n",
        "    --max_target_length=128  \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y8SoX9gj__0"
      },
      "source": [
        "# Pegasus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVGRaivhvDK_"
      },
      "source": [
        "\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class PegasusDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "      \n",
        "def prepare_data(model_name, \n",
        "                 train_texts, train_labels, \n",
        "                 val_texts=None, val_labels=None, \n",
        "                 test_texts=None, test_labels=None):\n",
        "  \"\"\"\n",
        "  Prepare input data for model fine-tuning\n",
        "  \"\"\"\n",
        "  tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  prepare_val = False if val_texts is None or val_labels is None else True\n",
        "  prepare_test = False if test_texts is None or test_labels is None else True\n",
        "\n",
        "  def tokenize_data(texts, labels):\n",
        "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
        "    decodings = tokenizer(labels, truncation=True, padding=True)\n",
        "    dataset_tokenized = PegasusDataset(encodings, decodings)\n",
        "    return dataset_tokenized\n",
        "\n",
        "  train_dataset = tokenize_data(train_texts, train_labels)\n",
        "  val_dataset = tokenize_data(val_texts, val_labels) if prepare_val else None\n",
        "  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset, tokenizer\n",
        "\n",
        "\n",
        "def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n",
        "  \"\"\"\n",
        "  Prepare configurations and base model for fine-tuning\n",
        "  \"\"\"\n",
        "  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "  if freeze_encoder:\n",
        "    for param in model.model.encoder.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  if val_dataset is not None:\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=output_dir,           # output directory\n",
        "      num_train_epochs=2000,           # total number of training epochs\n",
        "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
        "      per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n",
        "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
        "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
        "      evaluation_strategy='steps',     # evaluation strategy to adopt during training\n",
        "      eval_steps=100,                  # number of update steps before evaluation\n",
        "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "      weight_decay=0.01,               # strength of weight decay\n",
        "      logging_dir='./logs',            # directory for storing logs\n",
        "      logging_steps=10,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "      args=training_args,                  # training arguments, defined above\n",
        "      train_dataset=train_dataset,         # training dataset\n",
        "      eval_dataset=val_dataset,            # evaluation dataset\n",
        "      tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=output_dir,           # output directory\n",
        "      num_train_epochs=2000,           # total number of training epochs\n",
        "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
        "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
        "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
        "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "      weight_decay=0.01,               # strength of weight decay\n",
        "      logging_dir='./logs',            # directory for storing logs\n",
        "      logging_steps=10,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "      args=training_args,                  # training arguments, defined above\n",
        "      train_dataset=train_dataset,         # training dataset\n",
        "      tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "  return trainer\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "  # use Pegasus Large model as base for fine-tuning\n",
        "  train_df = pd.read_csv(\"Train_data.csv\")\n",
        "  valid_df = pd.read_csv(\"Valid_data.csv\")\n",
        "  model_name = 'google/pegasus-large'\n",
        "  train_dataset, _, _, tokenizer = prepare_data(model_name,train_df.meeting.tolist() , train_df.Summary.tolist())\n",
        "  valid_dataset,_,_,_ = prepare_data('google/pegasus-large',valid_df.meeting.tolist(),valid_df.Summary.tolist())\n",
        "  trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset,valid_dataset)\n",
        "  trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2RdUsWaPyq_",
        "outputId": "1a6451ac-39fd-4746-ad8c-e796221ac7ab"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 16 14:06:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx3G-cYCkiAc"
      },
      "source": [
        "# INFERENCE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNpYyS6Ikkf7"
      },
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "test_data = pd.read_csv(\"Test_data.csv\")\n",
        "\n",
        "src_text = test_data.meeting.tolist()[10:] \n",
        "\n",
        "#print(len(src_text))\n",
        "model_name = \"bart-large-5\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "#model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model =  AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
        "translated = model.generate(**batch)\n",
        "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "my_dict = {\n",
        "    \"preds\" : tgt_text,\n",
        "    \"actual\": test_data.Summary.tolist()[10:]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(my_dict)\n",
        "df.to_csv(\"predictions_next.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L72reSFsPVIF"
      },
      "source": [
        "# Inference *RESULTS* For Different Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cFKa-orQPob"
      },
      "source": [
        "Pegasus(Checkpoint 2000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVXtF56hPWfb"
      },
      "source": [
        "pred1 = pd.read_csv(\"predictions.csv\")\n",
        "pred2 = pd.read_csv(\"predictions_next.csv\")\n",
        "\n",
        "join = [pred1 , pred2]\n",
        "\n",
        "df_joined = pd.concat(join)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Cxr8F1PsCh",
        "outputId": "fc3dc20c-2f60-4eea-becd-7c18f13f65ea"
      },
      "source": [
        "len(df_joined)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFF3HKFyPwVc",
        "outputId": "5c5b9c1b-8b4c-4fbc-d788-4dbe4ca2c143"
      },
      "source": [
        "metric.compute(predictions = df_joined.preds.tolist(),references=df_joined.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.40439701877823314, recall=0.38630733460681654, fmeasure=0.3937626430485465), mid=Score(precision=0.4444366393125837, recall=0.4237678142916943, fmeasure=0.42624927062594753), high=Score(precision=0.48068321988116774, recall=0.4625331467549687, fmeasure=0.45906982125913903)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.12458523703290367, recall=0.12073949480832438, fmeasure=0.12098769475005403), mid=Score(precision=0.15433596561299567, recall=0.1490883644094902, fmeasure=0.14983723438068564), high=Score(precision=0.18997105872123438, recall=0.1813915473923218, fmeasure=0.1839126798822726)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.23392570618320602, recall=0.22357771669528104, fmeasure=0.2267561221269161), mid=Score(precision=0.2570639066482677, recall=0.2485966011135103, fmeasure=0.24852690345716782), high=Score(precision=0.2847828492216706, recall=0.27456540082606723, fmeasure=0.27219113738748474)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.2352318934201949, recall=0.2217772849550726, fmeasure=0.22636120574161087), mid=Score(precision=0.25621886431908114, recall=0.24796480018838463, fmeasure=0.24792221325530986), high=Score(precision=0.2849584156309286, recall=0.27236498199428216, fmeasure=0.2714551834863328))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1CALPukQCo_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGFTmgThRGUI"
      },
      "source": [
        "Pegasus(checkpoint 500)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYS4RKsRIRH",
        "outputId": "f733076c-46df-47c7-c6f5-8ea339b08561"
      },
      "source": [
        "pred1 = pd.read_csv(\"predictions.csv\")\n",
        "pred2 = pd.read_csv(\"predictions_next.csv\")\n",
        "\n",
        "join = [pred1 , pred2]\n",
        "\n",
        "df_joined = pd.concat(join)\n",
        "\n",
        "print(len(df_joined))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRmu4ymJRJeg",
        "outputId": "6e4ed9ad-70f6-4564-a65c-f7bf695c92b1"
      },
      "source": [
        "metric.compute(predictions = df_joined.preds.tolist(),references=df_joined.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.40211277615885865, recall=0.39234667365282516, fmeasure=0.397605136899324), mid=Score(precision=0.43421213741803166, recall=0.4269870354465292, fmeasure=0.425449913878605), high=Score(precision=0.46671674011468645, recall=0.4607441850197499, fmeasure=0.4520415536233954)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.1213129388243323, recall=0.12117196321727253, fmeasure=0.12037421687772198), mid=Score(precision=0.14781681839745286, recall=0.14550699052105232, fmeasure=0.14521575661738373), high=Score(precision=0.17696585317985492, recall=0.1699515278250861, fmeasure=0.17097294905866073)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.23003516973343985, recall=0.2271096641154576, fmeasure=0.2293651565691293), mid=Score(precision=0.25235416905945407, recall=0.25030817891351265, fmeasure=0.24875347871846643), high=Score(precision=0.2781784928682444, recall=0.27372597716911284, fmeasure=0.27010109520837977)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.23138060640867825, recall=0.22543323010514463, fmeasure=0.22915474170136332), mid=Score(precision=0.25179369382988614, recall=0.24944987505607086, fmeasure=0.248233251015974), high=Score(precision=0.27818514285924106, recall=0.2744213451193504, fmeasure=0.2695691697273429))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbdfeEf6Se1k"
      },
      "source": [
        "Pegasus(Checkpoint 1500)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYZGd3JjShPC",
        "outputId": "997df631-d517-4ffd-9351-b306b6bb5bca"
      },
      "source": [
        "pred1 = pd.read_csv(\"predictions.csv\")\n",
        "pred2 = pd.read_csv(\"predictions_next.csv\")\n",
        "\n",
        "join = [pred1 , pred2]\n",
        "\n",
        "df_joined = pd.concat(join)\n",
        "\n",
        "print(len(df_joined))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4CB3IikSkhH",
        "outputId": "e16f27a5-547a-4df1-caf0-029506734448"
      },
      "source": [
        "metric.compute(predictions = df_joined.preds.tolist(),references=df_joined.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.406699465144985, recall=0.38282560762996654, fmeasure=0.39488096221208757), mid=Score(precision=0.4430835774347117, recall=0.4192634558031275, fmeasure=0.4257134687893359), high=Score(precision=0.4827872825118298, recall=0.4568455613621107, fmeasure=0.4586526166012035)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.1298468056918049, recall=0.1249140826893274, fmeasure=0.12582238593977754), mid=Score(precision=0.1590850174160227, recall=0.15163412024877954, fmeasure=0.15399441035493955), high=Score(precision=0.19682900898743136, recall=0.1839056341745951, fmeasure=0.1884435258306613)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.2372090792494723, recall=0.22263049808985003, fmeasure=0.22804472301095652), mid=Score(precision=0.258937481798605, recall=0.24651447523816974, fmeasure=0.24994804432493223), high=Score(precision=0.2896825262701912, recall=0.27139490235137764, fmeasure=0.27352524796502065)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.23654865833027794, recall=0.2219981410366915, fmeasure=0.22884517247976477), mid=Score(precision=0.2585278083264298, recall=0.24595368347634244, fmeasure=0.24916100557296003), high=Score(precision=0.2874493929286795, recall=0.2699033738076099, fmeasure=0.2720747055014718))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Rpixe6fQwt"
      },
      "source": [
        "BART LARGE-XSUM MODEL EPOCHS 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O45K00SSfTmC",
        "outputId": "36ac2a02-52b7-4994-da05-949729fda711"
      },
      "source": [
        "pred1 = pd.read_csv(\"predictions.csv\")\n",
        "pred2 = pd.read_csv(\"predictions_next.csv\")\n",
        "\n",
        "join =       [pred1 , pred2]\n",
        "\n",
        "df_joined = pd.concat(join)\n",
        "\n",
        "print(len(df_joined))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ipvYuhhvyO",
        "outputId": "b17931c6-35bc-46a5-e6ee-2de83ba0a904"
      },
      "source": [
        "metric.compute(predictions = df_joined.preds.tolist(),references=df_joined.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.5746671827735507, recall=0.19057381286383798, fmeasure=0.28595163965380466), mid=Score(precision=0.6054803684635222, recall=0.21178198469275838, fmeasure=0.3107321986264726), high=Score(precision=0.640777504464937, recall=0.2333606758246301, fmeasure=0.33676334909990996)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.23071877474986124, recall=0.0778220005262467, fmeasure=0.11661006295900479), mid=Score(precision=0.2681107409098134, recall=0.0926059364967537, fmeasure=0.13671023657264827), high=Score(precision=0.304030092745855, recall=0.10854956868746374, fmeasure=0.1571748869784799)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.4018138514101452, recall=0.13379287342769194, fmeasure=0.2002756288395219), mid=Score(precision=0.4336514513239581, recall=0.15212434148001341, fmeasure=0.2234465283657594), high=Score(precision=0.4708245299885798, recall=0.17100546840634606, fmeasure=0.246767064520745)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.40119169470466637, recall=0.13410204127364633, fmeasure=0.2005903688404831), mid=Score(precision=0.4336935523047383, recall=0.15196351989481743, fmeasure=0.223236310665212), high=Score(precision=0.47389621695689765, recall=0.17076976901756494, fmeasure=0.2463213947832201))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJXKIzoAmYGJ"
      },
      "source": [
        "BART LARGE-XSUM MODEL EPOCHS 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWxgusfSmZrp",
        "outputId": "5590de47-1acd-4425-8b69-d94c4754b238"
      },
      "source": [
        "pred1 = pd.read_csv(\"predictions.csv\")\n",
        "pred2 = pd.read_csv(\"predictions_next.csv\")\n",
        "\n",
        "join = [pred1 , pred2]\n",
        "\n",
        "df_joined = pd.concat(join)\n",
        "\n",
        "print(len(df_joined))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhNULDu8maEh",
        "outputId": "a4918a4b-a32e-4e44-96a6-65117ae96769"
      },
      "source": [
        "metric.compute(predictions = df_joined.preds.tolist(),references=df_joined.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.5278100195294285, recall=0.17254989359927053, fmeasure=0.2605829458817205), mid=Score(precision=0.5695345083320745, recall=0.19298840811009993, fmeasure=0.2853467377800024), high=Score(precision=0.6223712381940615, recall=0.22118575023977785, fmeasure=0.3197053993817845)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.189251483574894, recall=0.06289894563474789, fmeasure=0.09427330896780932), mid=Score(precision=0.2356845420061302, recall=0.0785780448530408, fmeasure=0.11645810679746713), high=Score(precision=0.2951388453150923, recall=0.10719152450778976, fmeasure=0.1534538532008188)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.3640071998847442, recall=0.11990640700539144, fmeasure=0.18054519244975445), mid=Score(precision=0.40377038201112636, recall=0.1382703340090887, fmeasure=0.20361809431037303), high=Score(precision=0.4509006948720759, recall=0.16229406104793925, fmeasure=0.23341003215273992)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.36510348136089626, recall=0.1202827631798004, fmeasure=0.18073014938462842), mid=Score(precision=0.4044838062935514, recall=0.1382742371240976, fmeasure=0.20398365677615032), high=Score(precision=0.45092186035931575, recall=0.16201334624487132, fmeasure=0.2335791528632218))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAp2fkTo4Yoa"
      },
      "source": [
        "T5(epoch 5 ,gradient clip at 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zikbIyYGmbkW"
      },
      "source": [
        "df = pd.read_csv(\"/content/Predictions_T5_5_Sclip.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewNzEieZ4tR4",
        "outputId": "3c62b5d5-bbbe-4008-8a30-0d5327c9b2af"
      },
      "source": [
        "metric.compute(predictions = df.preds.tolist(),references=df.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.4595323283108672, recall=0.29502399485672376, fmeasure=0.3586385758622941), mid=Score(precision=0.4954428361948009, recall=0.3231773589633429, fmeasure=0.3866229151874762), high=Score(precision=0.5244657927718478, recall=0.354457017807162, fmeasure=0.4132528945009049)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.15301713106698206, recall=0.09943085744505108, fmeasure=0.1191041949933987), mid=Score(precision=0.18297866228652954, recall=0.11983030282632462, fmeasure=0.1429878003861625), high=Score(precision=0.21128559317167508, recall=0.14325976052255787, fmeasure=0.16559942745104897)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.2779882853457587, recall=0.17849925347339185, fmeasure=0.21764326508974954), mid=Score(precision=0.3019269133345725, recall=0.19864709337554576, fmeasure=0.23623259620598341), high=Score(precision=0.32759840533334617, recall=0.21892206326297034, fmeasure=0.25450298555609574)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.2773260100288315, recall=0.17807729964693175, fmeasure=0.21705973735210435), mid=Score(precision=0.30119010829886017, recall=0.19787726007549636, fmeasure=0.23587537279164517), high=Score(precision=0.3258977360633274, recall=0.21763290124960824, fmeasure=0.25372327888481866))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtJEroqT40Sj"
      },
      "source": [
        "T5(EPOCH 5, SWA(stochastic Weight Averaging)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL1zU6pz4xmj"
      },
      "source": [
        "df = pd.read_csv(\"/content/Predictions_T5_5_SWA.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJBVZ6uh45vI",
        "outputId": "51272cde-1892-4729-f7c4-de8579bdf2af"
      },
      "source": [
        "metric.compute(predictions = df.preds.tolist(),references=df.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.42743105860063046, recall=0.26913376770816044, fmeasure=0.33208205581741773), mid=Score(precision=0.4553977108854025, recall=0.2936530721412022, fmeasure=0.35163382491497064), high=Score(precision=0.4858160638348559, recall=0.32157321090711183, fmeasure=0.37458863972996254)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.11671719907508529, recall=0.07487920686988073, fmeasure=0.09061918505637574), mid=Score(precision=0.14384684641949858, recall=0.09396966038337073, fmeasure=0.11218612095527998), high=Score(precision=0.17088031109003626, recall=0.11425425131450291, fmeasure=0.13236537485632066)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.25074407377493585, recall=0.15703721665058792, fmeasure=0.19315434409680732), mid=Score(precision=0.2708404923997352, recall=0.17570121167542557, fmeasure=0.21014983334891119), high=Score(precision=0.29143494907877315, recall=0.1951415912325562, fmeasure=0.2258556497554936)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.2509360373723179, recall=0.15789951155482845, fmeasure=0.1941652595958916), mid=Score(precision=0.2708607947945073, recall=0.17496595958693062, fmeasure=0.21022107653428534), high=Score(precision=0.2924896316855768, recall=0.19544634310606357, fmeasure=0.22671576430890547))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBVRME145AuI"
      },
      "source": [
        "T5(EPOCH 5 ,LR =5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b-p44h94-9k"
      },
      "source": [
        "df = pd.read_csv(\"/content/Predictions_T5_5_5e-4.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3RHo7fg5Nwd",
        "outputId": "2bdf86a3-7756-47ab-f525-c45bca0ae2f6"
      },
      "source": [
        "metric.compute(predictions = df.preds.tolist(),references=df.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.45673921606631496, recall=0.28658059920007817, fmeasure=0.3527037724886849), mid=Score(precision=0.48718814853027914, recall=0.31109946358133966, fmeasure=0.3752302173720957), high=Score(precision=0.5137265417941873, recall=0.3317867779121553, fmeasure=0.3928223740251708)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.13456042401082516, recall=0.08516357735932743, fmeasure=0.10368824940253416), mid=Score(precision=0.1584198655667381, recall=0.1014952196192484, fmeasure=0.12286989252356749), high=Score(precision=0.18255176953787308, recall=0.11794421779796727, fmeasure=0.14026875023722402)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.2599808672886207, recall=0.16178695311284844, fmeasure=0.1998102870284882), mid=Score(precision=0.2780782270050828, recall=0.17873629844315658, fmeasure=0.21496881659254846), high=Score(precision=0.29627542350521263, recall=0.19645994661702038, fmeasure=0.2294537126187311)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.2599110016692298, recall=0.16124203294519487, fmeasure=0.19885500272401907), mid=Score(precision=0.2778623531939661, recall=0.1782377211502516, fmeasure=0.2145798760336739), high=Score(precision=0.2958876212756791, recall=0.19436475264836375, fmeasure=0.22936286521881372))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6edx2mj5VfO"
      },
      "source": [
        "T5(Epoch 3, LR = 5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kt3MIJX5TW7"
      },
      "source": [
        "df = pd.read_csv(\"//content/Predictions_T5_3_5e-4.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stN8rA-q5ZlN",
        "outputId": "531abcd7-c554-4cc1-95a6-ef94587a72f8"
      },
      "source": [
        "metric.compute(predictions = df.preds.tolist(),references=df.actual.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.4460893396702219, recall=0.28797903478612047, fmeasure=0.35140629368487364), mid=Score(precision=0.49025058142958056, recall=0.3148715397960282, fmeasure=0.3780338036991201), high=Score(precision=0.5266273896659619, recall=0.3426143433213742, fmeasure=0.40308288668605463)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.1366658800626159, recall=0.08668727863246513, fmeasure=0.10587417641906405), mid=Score(precision=0.16485325366102493, recall=0.10613776960291618, fmeasure=0.1273194040712594), high=Score(precision=0.19139232931654318, recall=0.12583690448187995, fmeasure=0.14797175875644353)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.28378451151266654, recall=0.1832237182115016, fmeasure=0.22335848846356934), mid=Score(precision=0.307487176228171, recall=0.19844833114948143, fmeasure=0.23771466482413225), high=Score(precision=0.33160708092402297, recall=0.21602500532279442, fmeasure=0.2511992230178269)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.2839381291403822, recall=0.18104709618027645, fmeasure=0.22223913210249557), mid=Score(precision=0.3070978513315606, recall=0.19799685947490234, fmeasure=0.2373930486631322), high=Score(precision=0.3328949177367484, recall=0.21516625516954122, fmeasure=0.25258950429420657))}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzUsE3ZK5eiw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2cCCbpt5TxF"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # predictions, labels = eval_pred\n",
        "    # decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # # Replace -100 in the labels as we can't decode them.\n",
        "    # labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # # Rouge expects a newline after each sentence\n",
        "    # decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    # decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    decoded_preds = eval_pred.preds.tolist()\n",
        "    decoded_labels = eval_pred.actual.tolist()\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    # result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "   \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkiY-vMz5VQ7"
      },
      "source": [
        "df = pd.read_csv(\"/content/Predictions_T5_5_Sclip.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Aii1Q5Z6hwy",
        "outputId": "7d06cde2-32ad-4a2a-cf95-f96753a1c6e7"
      },
      "source": [
        "compute_metrics(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 41.5455, 'rouge2': 15.2441, 'rougeL': 24.8294, 'rougeLsum': 24.7878}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0cMzWgq6p0J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}